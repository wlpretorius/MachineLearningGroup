{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "def clar(y: np.ndarray, X: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Cumulative LGD Accuracy Ratio (CLAR).\n",
    "\n",
    "    CLAR measures the ability of predicted LGD categories to discriminate\n",
    "    realized LGD values according to Ozdemir and Miu 2009.\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Vector of realized LGD values\n",
    "        X (np.ndarray): Vector of predicted LGD values\n",
    "\n",
    "    Returns:\n",
    "        CLAR value for the predicted and realized LGD categories (np.float)\n",
    "        Share of observations as a numpy array (np.ndarray)\n",
    "        Cumulative share of correctly assigned LGD values as a numpy array (np.ndarray)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If either 'X' or 'y' contains NA values\n",
    "        ValueError: If 'X' and 'y' have different lengths\n",
    "\n",
    "    References:\n",
    "        Ozdemir, B., Miu, P., 2009. Basel II Implementation. A Guide to\n",
    "        Developing and Validating a Compliant Internal Risk Rating System.\n",
    "        McGraw-Hill, USA.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check for NA values and length mismatch\n",
    "    if any(pd.isna(X)) or any(pd.isna(y)):\n",
    "        raise ValueError(\"Both 'X' and 'y' must not contain NA values\")\n",
    "    \n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"Both 'X' and 'y' must be of the same length\")\n",
    "\n",
    "    # Number of observations\n",
    "    nx = len(X)\n",
    "\n",
    "    # Get sorted unique classes from both X and y\n",
    "    classes = sorted(set(X).union(set(y)), reverse=True)\n",
    "    \n",
    "    # Count the occurrences of each class in X\n",
    "    num = [np.sum(X == cls) for cls in classes]\n",
    "    \n",
    "    # Cumulative sum of occurrences\n",
    "    cnum = np.cumsum(num)\n",
    "    \n",
    "    # Sort X and y based on the sorted order of X in descending order\n",
    "    sorted_indices = np.argsort(X)[::-1]\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Initialize the array to store the cumulative correct counts\n",
    "    correct_cumulative = np.zeros(len(classes))\n",
    "    \n",
    "    # Calculate cumulative correct counts for each class\n",
    "    for i, cls in enumerate(classes[:-1]):\n",
    "        if cnum[i] > 0:\n",
    "            correct_cumulative[i] = np.sum(y_sorted[:cnum[i]] >= cls)\n",
    "    \n",
    "    # Normalize by the number of observations\n",
    "    correct_cumulative /= nx\n",
    "    correct_cumulative[-1] = 1  # Last class should always be 1\n",
    "    \n",
    "    # Calculate the cumulative share of observations\n",
    "    obs_cumulative = cnum / nx\n",
    "    \n",
    "    # Calculate the area under the curve (AUC) using trapezoidal rule\n",
    "    auc = 0.0\n",
    "    for i in range(1, len(classes)):\n",
    "        base_width = obs_cumulative[i] - obs_cumulative[i - 1]\n",
    "        height_left = correct_cumulative[i - 1]\n",
    "        height_right = correct_cumulative[i]\n",
    "        trapezoid_area = base_width * (height_left + height_right) / 2\n",
    "        auc += trapezoid_area\n",
    "    \n",
    "    # CLAR value is twice the area under the curve\n",
    "    clar_value = auc * 2\n",
    "    \n",
    "    return clar_value, obs_cumulative, correct_cumulative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clar(y, y_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def clar2(y: np.ndarray, X: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Cumulative LGD Accuracy Ratio (CLAR).\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Vector of realized LGD values\n",
    "        X (np.ndarray): Vector of predicted LGD values\n",
    "\n",
    "    Returns:\n",
    "        CLAR value (float), Share of observations (np.ndarray), \n",
    "        Cumulative share of correctly assigned LGD values (np.ndarray)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    def validate_inputs(y, X):\n",
    "        if any(pd.isna(X)) or any(pd.isna(y)):\n",
    "            raise ValueError(\"Both 'X' and 'y' must not contain NA values\")\n",
    "        if len(X) != len(y):\n",
    "            raise ValueError(\"Both 'X' and 'y' must be of the same length\")\n",
    "    \n",
    "    # Calculate the cumulative correct assignments\n",
    "    def calculate_cumulative_correct(y_sorted, classes, cnum):\n",
    "        correct_cumulative = np.zeros(len(classes))\n",
    "        for i in range(len(classes) - 1):\n",
    "            if cnum[i] > 0:\n",
    "                correct_cumulative[i] = np.sum(y_sorted[:cnum[i]] >= classes[i])\n",
    "        correct_cumulative /= len(y_sorted)\n",
    "        correct_cumulative[-1] = 1\n",
    "        return correct_cumulative\n",
    "    \n",
    "    # Calculate the Area Under the Curve (AUC)\n",
    "    def calculate_auc(obs_cumulative, correct_cumulative):\n",
    "        auc = 0.0\n",
    "        for i in range(1, len(obs_cumulative)):\n",
    "            base_width = obs_cumulative[i] - obs_cumulative[i - 1]\n",
    "            height_left = correct_cumulative[i - 1]\n",
    "            height_right = correct_cumulative[i]\n",
    "            trapezoid_area = base_width * (height_left + height_right) / 2\n",
    "            auc += trapezoid_area\n",
    "        return auc\n",
    "    \n",
    "    # Main logic\n",
    "    validate_inputs(y, X)\n",
    "    \n",
    "    nx = len(X)\n",
    "    classes = sorted(set(X).union(set(y)), reverse=True)\n",
    "    num = [np.sum(X == cls) for cls in classes]\n",
    "    cnum = np.cumsum(num)\n",
    "    \n",
    "    sorted_indices = np.argsort(X)[::-1]\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    correct_cumulative = calculate_cumulative_correct(y_sorted, classes, cnum)\n",
    "    obs_cumulative = cnum / nx\n",
    "    \n",
    "    auc = calculate_auc(obs_cumulative, correct_cumulative)\n",
    "    clar_value = auc * 2\n",
    "    \n",
    "    return clar_value, obs_cumulative, correct_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def loss_capture_ratio(y: np.ndarray, X: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Loss Capture Ratio (LCR).\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Vector of actual values\n",
    "        X (np.ndarray): Vector of predicted values\n",
    "\n",
    "    Returns:\n",
    "        LCR value (float), Ideal model (np.ndarray), Ideal observations (np.ndarray),\n",
    "        Predicted model (np.ndarray), Predicted observations (np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if any(pd.isna(X)) or any(pd.isna(y)):\n",
    "        raise ValueError(\"Both 'X' and 'y' must not contain NA values\")\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"Both 'X' and 'y' must be of the same length\")\n",
    "    if len(set(y)) == 1:\n",
    "        raise ValueError(\"Actual values 'y' must not be constant\")\n",
    "\n",
    "    # Determine the perfect model and population\n",
    "    ideal = np.flip(np.sort(y))\n",
    "    ideal_model = ideal.cumsum() / ideal.sum()\n",
    "    ideal_populations = np.insert(np.arange(1, ideal_model.size + 1) / ideal_model.size, 0, 0)\n",
    "    ideal_model = np.insert(ideal_model, 0, 0)\n",
    "\n",
    "    # Determine the developed model and population\n",
    "    data = pd.DataFrame(data={\"actual\": y, \"predicted\": X})\n",
    "    developed = (\n",
    "        pd.merge(\n",
    "            data,\n",
    "            (data.groupby(\"predicted\")[\"actual\"].mean()).to_frame(),\n",
    "            how=\"outer\",\n",
    "            left_on=\"predicted\",\n",
    "            right_index=True,\n",
    "        )\n",
    "        .iloc[:, [1, 2]]\n",
    "        .sort_values(ascending=False, by=\"predicted\")\n",
    "        .iloc[:, 1]\n",
    "        .values\n",
    "    )\n",
    "    developed_model = developed.cumsum() / developed.sum()\n",
    "    developed_populations = np.insert(np.arange(1, developed_model.size + 1) / developed_model.size, 0, 0)\n",
    "    developed_model = np.insert(developed_model, 0, 0)\n",
    "\n",
    "    # Compute the areas under the perfect and developed curves\n",
    "    perfect_area = np.trapz(ideal_model, ideal_populations)\n",
    "    developed_area = np.trapz(developed_model, developed_populations)\n",
    "\n",
    "    # Calculate the accuracy ratio\n",
    "    accuracy_ratio = (developed_area - 0.5) / (perfect_area - 0.5)\n",
    "\n",
    "    return accuracy_ratio, ideal_model, ideal_populations, developed_model, developed_populations\n",
    "\n",
    "# Example usage\n",
    "y = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "X = np.array([0.2, 0.3, 0.5, 0.7])\n",
    "lcr_value, ideal_model, ideal_populations, developed_model, developed_populations = loss_capture_ratio(y, X)\n",
    "print(f\"LCR Value: {lcr_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LossCaptureRatio class for comparison\n",
    "import attr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "class LossCaptureRatio:\n",
    "    def __init__(self, actual: np.ndarray, predicted: np.ndarray):\n",
    "        self.actual = actual\n",
    "        self.predicted = predicted\n",
    "\n",
    "    def compute_accuracy_ratio(self) -> float:\n",
    "        ideal_model, ideal_populations = self._determine_perfect_model_and_population()\n",
    "        developed_model, developed_populations = self._determine_developed_model_and_population()\n",
    "\n",
    "        perfect_area = np.trapz(ideal_model, ideal_populations)\n",
    "        developed_area = np.trapz(developed_model, developed_populations)\n",
    "\n",
    "        accuracy_ratio = (developed_area - 0.5) / (perfect_area - 0.5)\n",
    "        return accuracy_ratio\n",
    "\n",
    "    def _determine_perfect_model_and_population(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        ideal = np.flip(np.sort(self.actual))\n",
    "        model = ideal.cumsum() / ideal.sum()\n",
    "        populations = np.insert(np.arange(1, model.size + 1) / model.size, 0, 0)\n",
    "        return np.insert(model, 0, 0), populations\n",
    "\n",
    "    def _determine_developed_model_and_population(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        data = pd.DataFrame(data={\"actual\": self.actual, \"predicted\": self.predicted})\n",
    "        developed = (\n",
    "            pd.merge(\n",
    "                data,\n",
    "                (data.groupby(\"predicted\")[\"actual\"].mean()).to_frame(),\n",
    "                how=\"outer\",\n",
    "                left_on=\"predicted\",\n",
    "                right_index=True,\n",
    "            )\n",
    "            .iloc[:, [1, 2]]\n",
    "            .sort_values(ascending=False, by=\"predicted\")\n",
    "            .iloc[:, 1]\n",
    "            .values\n",
    "        )\n",
    "        model = developed.cumsum() / developed.sum()\n",
    "        populations = np.insert(np.arange(1, model.size + 1) / model.size, 0, 0)\n",
    "        return np.insert(model, 0, 0), populations\n",
    "\n",
    "# Example usage for comparison\n",
    "y = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "X = np.array([0.2, 0.3, 0.5, 0.7])\n",
    "\n",
    "lcr = LossCaptureRatio(actual=y, predicted=X)\n",
    "lcr_value = lcr.compute_accuracy_ratio()\n",
    "print(f\"LossCaptureRatio Value: {lcr_value}\")\n",
    "\n",
    "clar_value, _, _, _, _ = clar2(y, X)\n",
    "print(f\"CLAR Value: {clar_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _determine_perfect_model_and_population(self) -> tuple:\n",
    "        df = self.data.copy().sort_values(\n",
    "            by=[ColumnName.WEIGHTED_DEFAULTS.value], ascending=False, ignore_index=True\n",
    "        )\n",
    "        model = (\n",
    "            df[ColumnName.WEIGHTED_DEFAULTS.value]\n",
    "        ).cumsum().values / self.weighted_defaults_sum\n",
    "        population = (df[ColumnName.WEIGHT.value]).cumsum().values / self.weights_sum\n",
    "        model = np.insert(model, 0, 0)\n",
    "        population = np.insert(population, 0, 0)\n",
    " \n",
    "        return model, population\n",
    " \n",
    "def _determine_developed_model_and_population(self) -> tuple:\n",
    "    df = (\n",
    "        self.data.sort_values(by=[ColumnName.PREDICTED.value], ascending=False)\n",
    "        .groupby([ColumnName.PREDICTED.value], sort=False)\n",
    "        .sum()\n",
    "    )\n",
    "    model = (\n",
    "        df[ColumnName.WEIGHTED_DEFAULTS.value].cumsum().values\n",
    "        / self.weighted_defaults_sum\n",
    "    )\n",
    "    population = df[ColumnName.WEIGHT.value].cumsum().values / self.weights_sum\n",
    "    model = np.insert(model, 0, 0)\n",
    "    population = np.insert(population, 0, 0)\n",
    "\n",
    "    return model, population\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
